# Crowdfunding_ETL

Project 2- ETL

Crowdfunding_ETL
This project demonstrates the ability to build an ETL pipeline.
The tools used are Python, Pandas, and Python dictionary methods. The data used is the crowdfunding data. After processing the data and creating four CSV files, a schema is created to upload the CSVs data into a Postgres database.

Repository Structure
ETL_Pipeline:

ETL_Mini_Project_MJama.ipynb: File containing code to transform original CSV files into four, cleaned CSV files.
QuickDBD-crowdfunding_db_schema.sql: SQL code generated by using the QuickDBD tool, representing the database schema.
Resources Folder: Contains the necessary CSV files for creating the new CSV files.
Output: Contains the four new CSV files created.

Instructions to Run the Codes

1. Set Up the Database and Tables
   Open and Execute the Schema Script:

Open PGAdmin and create a database called crowdfunding_db

Open the QuickDBD-crowdfunding_db_schema.sql file in the new crowdfunding_db

To ensure code can be re-run, use the following drop statements before the schema code:

DROP TABLE IF EXISTS category;
DROP TABLE IF EXISTS subcategory;
DROP TABLE IF EXISTS contacts;
DROP TABLE IF EXISTS campaign;
Execute the entire script to create the tables.

2. Import the Data
   After executing the schema, import the CSV data in the output folder into the database tables in the following order:

category
subcategory
contacts
campaign
You can import the data using the Import/Export features in PGAdmin.

3. Run SELECT Statements
   Open a new query and run the following SELECT statements to ensure the tables function properly:

SELECT _ FROM category;
SELECT _ FROM subcategory;
SELECT _ FROM contacts;
SELECT _ FROM campaign;
